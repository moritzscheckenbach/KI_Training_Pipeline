{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dce0dc2",
   "metadata": {},
   "source": [
    "## Example of a Neural Network Pipeline with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7ccc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorBoard is available!\n"
     ]
    }
   ],
   "source": [
    "# Import all necessary modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "# Check if tensorboard is installed, if not install it\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    print(\"‚úÖ TensorBoard is available!\")\n",
    "except ImportError:\n",
    "    print(\"Tensorboard is not installed. Installing now...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'tensorboard'])\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    print(\"‚úÖ TensorBoard installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f66dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Vision Transformer (ViT) implementation\n",
    "class SimpleViT(nn.Module):\n",
    "    def __init__(self, image_size=28, patch_size=7, num_classes=10, dim=64, depth=4, heads=4, mlp_dim=128):\n",
    "        super().__init__()\n",
    "        assert image_size % patch_size == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        patch_dim = patch_size * patch_size\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "        self.dim = dim\n",
    "        self.patch_embedding = nn.Linear(patch_dim, dim)\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, dim))\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=dim, nhead=heads, dim_feedforward=mlp_dim),\n",
    "            num_layers=depth\n",
    "        )\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.reshape(B, C, H // self.patch_size, self.patch_size, W // self.patch_size, self.patch_size)\n",
    "        x = x.permute(0, 2, 4, 1, 3, 5).reshape(B, -1, C * self.patch_size * self.patch_size)\n",
    "        x = self.patch_embedding(x)\n",
    "        x = x + self.pos_embedding\n",
    "        x = self.transformer(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.mlp_head(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2bb6e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Swin Transformer implementation\n",
    "class SimpleSwinTransformer(nn.Module):\n",
    "    def __init__(self, img_size=28, patch_size=4, in_chans=1, num_classes=10,\n",
    "                embed_dim=96, depths=[2, 2], num_heads=[3, 6],\n",
    "                window_size=7, mlp_ratio=4., drop_rate=0., drop_path_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_size = patch_size\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # Patch embedding layer\n",
    "        self.patch_embed = PatchEmbed(\n",
    "            img_size=img_size, patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim)\n",
    "        num_patches = self.patch_embed.num_patches\n",
    "        \n",
    "        # Absolute position embedding\n",
    "        self.absolute_pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        \n",
    "        # Build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            layer = BasicLayer(\n",
    "                dim=int(embed_dim * 2 ** i_layer),\n",
    "                input_resolution=(img_size // patch_size // (2 ** i_layer),\n",
    "                                img_size // patch_size // (2 ** i_layer)),\n",
    "                depth=depths[i_layer],\n",
    "                num_heads=num_heads[i_layer],\n",
    "                window_size=window_size,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                drop=drop_rate,\n",
    "                drop_path=drop_path_rate,\n",
    "                downsample=PatchMerging if (i_layer < self.num_layers - 1) else None)\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        # Classification head\n",
    "        self.norm = nn.LayerNorm(int(embed_dim * 2 ** (self.num_layers - 1)))\n",
    "        self.head = nn.Linear(int(embed_dim * 2 ** (self.num_layers - 1)), num_classes)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Patch embedding\n",
    "        x = self.patch_embed(x)  # B, L, C\n",
    "        x = x + self.absolute_pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        \n",
    "        # Forward through layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Classification head\n",
    "        x = self.norm(x)  # B, L, C\n",
    "        x = x.mean(dim=1)  # Global average pooling: B, C\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\"Image to Patch Embedding\"\"\"\n",
    "    def __init__(self, img_size=28, patch_size=4, in_chans=1, embed_dim=96):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.patches_resolution = [img_size // patch_size, img_size // patch_size]\n",
    "        self.num_patches = self.patches_resolution[0] * self.patches_resolution[1]\n",
    "        \n",
    "        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.proj(x).flatten(2).transpose(1, 2)  # B, Ph*Pw, C\n",
    "        return x\n",
    "\n",
    "\n",
    "class WindowAttention(nn.Module):\n",
    "    \"\"\"Window based multi-head self attention (W-MSA) module\"\"\"\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        \n",
    "        # Relative position bias table\n",
    "        self.relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * window_size[0] - 1) * (2 * window_size[1] - 1), num_heads))\n",
    "        \n",
    "        # Get pair-wise relative position index\n",
    "        coords_h = torch.arange(self.window_size[0])\n",
    "        coords_w = torch.arange(self.window_size[1])\n",
    "        coords = torch.stack(torch.meshgrid([coords_h, coords_w], indexing='ij'))\n",
    "        coords_flatten = torch.flatten(coords, 1)\n",
    "        relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "        relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "        relative_coords[:, :, 0] += self.window_size[0] - 1\n",
    "        relative_coords[:, :, 1] += self.window_size[1] - 1\n",
    "        relative_coords[:, :, 0] *= 2 * self.window_size[1] - 1\n",
    "        relative_position_index = relative_coords.sum(-1)\n",
    "        self.register_buffer(\"relative_position_index\", relative_position_index)\n",
    "        \n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        \n",
    "        nn.init.trunc_normal_(self.relative_position_bias_table, std=0.02)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "        \n",
    "        relative_position_bias = self.relative_position_bias_table[self.relative_position_index.view(-1)].view(\n",
    "            self.window_size[0] * self.window_size[1], self.window_size[0] * self.window_size[1], -1)\n",
    "        relative_position_bias = relative_position_bias.permute(2, 0, 1).contiguous()\n",
    "        attn = attn + relative_position_bias.unsqueeze(0)\n",
    "        \n",
    "        if mask is not None:\n",
    "            nW = mask.shape[0]\n",
    "            attn = attn.view(B_ // nW, nW, self.num_heads, N, N) + mask.unsqueeze(1).unsqueeze(0)\n",
    "            attn = attn.view(-1, self.num_heads, N, N)\n",
    "            attn = attn.softmax(dim=-1)\n",
    "        else:\n",
    "            attn = attn.softmax(dim=-1)\n",
    "        \n",
    "        attn = self.attn_drop(attn)\n",
    "        \n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SwinTransformerBlock(nn.Module):\n",
    "    \"\"\"Swin Transformer Block\"\"\"\n",
    "    def __init__(self, dim, input_resolution, num_heads, window_size=7, shift_size=0,\n",
    "                mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        \n",
    "        if min(self.input_resolution) <= self.window_size:\n",
    "            self.shift_size = 0\n",
    "            self.window_size = min(self.input_resolution)\n",
    "            \n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=(self.window_size, self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop)\n",
    "        \n",
    "        self.drop_path = nn.Identity() if drop_path <= 0. else nn.Dropout(drop_path)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(mlp_hidden_dim, dim),\n",
    "            nn.Dropout(drop)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = x.view(B, H, W, C)\n",
    "        \n",
    "        # Cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "        \n",
    "        # Partition windows\n",
    "        x_windows = window_partition(shifted_x, self.window_size)\n",
    "        x_windows = x_windows.view(-1, self.window_size * self.window_size, C)\n",
    "        \n",
    "        # W-MSA/SW-MSA\n",
    "        attn_windows = self.attn(x_windows)\n",
    "        \n",
    "        # Merge windows\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)\n",
    "        \n",
    "        # Reverse cyclic shift\n",
    "        if self.shift_size > 0:\n",
    "            x = torch.roll(shifted_x, shifts=(self.shift_size, self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            x = shifted_x\n",
    "        x = x.view(B, H * W, C)\n",
    "        \n",
    "        # FFN\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class PatchMerging(nn.Module):\n",
    "    \"\"\"Patch Merging Layer\"\"\"\n",
    "    def __init__(self, input_resolution, dim):\n",
    "        super().__init__()\n",
    "        self.input_resolution = input_resolution\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "        self.norm = nn.LayerNorm(4 * dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        H, W = self.input_resolution\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "        assert H % 2 == 0 and W % 2 == 0, f\"x size ({H}*{W}) are not even.\"\n",
    "        \n",
    "        x = x.view(B, H, W, C)\n",
    "        \n",
    "        x0 = x[:, 0::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x1 = x[:, 1::2, 0::2, :]  # B H/2 W/2 C\n",
    "        x2 = x[:, 0::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x3 = x[:, 1::2, 1::2, :]  # B H/2 W/2 C\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # B H/2 W/2 4*C\n",
    "        x = x.view(B, -1, 4 * C)  # B H/2*W/2 4*C\n",
    "        \n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicLayer(nn.Module):\n",
    "    \"\"\"A basic Swin Transformer layer for one stage\"\"\"\n",
    "    def __init__(self, dim, input_resolution, depth, num_heads, window_size,\n",
    "                mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0.,\n",
    "                drop_path=0., downsample=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.input_resolution = input_resolution\n",
    "        self.depth = depth\n",
    "        \n",
    "        # Build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock(dim=dim, input_resolution=input_resolution,\n",
    "                        num_heads=num_heads, window_size=window_size,\n",
    "                        shift_size=0 if (i % 2 == 0) else window_size // 2,\n",
    "                        mlp_ratio=mlp_ratio,\n",
    "                        qkv_bias=qkv_bias, drop=drop, attn_drop=attn_drop,\n",
    "                        drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path)\n",
    "            for i in range(depth)])\n",
    "        \n",
    "        # Patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(input_resolution, dim=dim)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def window_partition(x, window_size):\n",
    "    \"\"\"Partition into non-overlapping windows\"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "\n",
    "\n",
    "def window_reverse(windows, window_size, H, W):\n",
    "    \"\"\"Reverse of window partition\"\"\"\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
    "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86772dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 'runs' directory already exists. Using existing logs directory...\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# check of run path exists and create if not\n",
    "if os.path.exists('runs'):\n",
    "    print(\"‚úÖ 'runs' directory already exists. Using existing logs directory...\")\n",
    "else:\n",
    "    print(\"‚ùó 'runs' directory does not exist. Creating new logs directory...\")\n",
    "    os.makedirs('runs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6972dd0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created with patch_size=7\n",
      "Initial resolution after patching: 4x4 = 4x4\n",
      "‚úÖ This ensures even dimensions for patch merging!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moritz_s/anaconda3/envs/KI_Pipeline/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "#model = SimpleViT() # or SimpleSwinTransformer()\n",
    "model = SimpleSwinTransformer() # or SimpleViT()\n",
    "# model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "print(f\"Model created with patch_size={model.patch_size}\")\n",
    "print(f\"Initial resolution after patching: {28//7}x{28//7} = 4x4\")\n",
    "print(\"‚úÖ This ensures even dimensions for patch merging!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101672aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorBoard writer created successfully!\n",
      "Logging to: runs/Aug06_09-35-25_Moritz-HP\n",
      "\n",
      "üèãÔ∏è Starting training...\n",
      "Batch 0, Loss: 2.4274\n",
      "Batch 10, Loss: 2.3069\n",
      "Batch 20, Loss: 2.3067\n",
      "Batch 30, Loss: 2.3092\n",
      "Batch 40, Loss: 2.3644\n",
      "Batch 50, Loss: 2.3401\n",
      "Batch 60, Loss: 2.2718\n",
      "Batch 70, Loss: 2.2712\n",
      "Batch 80, Loss: 2.0993\n",
      "Batch 90, Loss: 1.9156\n",
      "Batch 100, Loss: 1.6519\n",
      "\n",
      "‚úÖ Training complete!\n",
      "üìä TensorBoard logs saved to: runs/Aug06_09-35-25_Moritz-HP\n",
      "üåê Now run the TensorBoard launcher below to visualize the results!\n"
     ]
    }
   ],
   "source": [
    "# TensorBoard writer with automatic model type detection\n",
    "import datetime\n",
    "\n",
    "# Detect model type automatically\n",
    "model_type = type(model).__name__\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create descriptive experiment name\n",
    "experiment_name = f\"{model_type}_{timestamp}\"\n",
    "\n",
    "# Create TensorBoard writer with custom experiment name\n",
    "try:\n",
    "    writer = SummaryWriter(f'runs/{experiment_name}')\n",
    "    print(\"‚úÖ TensorBoard writer created successfully!\")\n",
    "    print(f\"üìä Experiment: {experiment_name}\")\n",
    "    print(f\"üìÅ Logging to: {writer.log_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating TensorBoard writer: {e}\")\n",
    "    # Fallback: create manual logs\n",
    "    import tempfile\n",
    "    temp_dir = tempfile.mkdtemp(prefix=f'tensorboard_{model_type}_')\n",
    "    writer = SummaryWriter(temp_dir)\n",
    "    print(f\"‚úÖ Using temporary directory: {temp_dir}\")\n",
    "\n",
    "# Training loop with enhanced logging\n",
    "print(f\"\\nüèãÔ∏è Starting training with {model_type}...\")\n",
    "model.train()\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    loss = criterion(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Log every 10 batches with model-specific naming\n",
    "    if batch_idx % 10 == 0:\n",
    "        writer.add_scalar(f'{model_type}/Loss_Train', loss.item(), batch_idx)\n",
    "        writer.add_scalar('Training/Loss', loss.item(), batch_idx)\n",
    "        print(f\"[{model_type}] Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    if batch_idx >= 100:  # limit for demo\n",
    "        break\n",
    "\n",
    "# Log final metrics with model info\n",
    "writer.add_scalar(f'{model_type}/Final_Loss', loss.item(), 0)\n",
    "writer.add_scalar('Final/TrainingLoss', loss.item(), 0)\n",
    "\n",
    "# Add model parameters as text for comparison\n",
    "model_params = sum(p.numel() for p in model.parameters())\n",
    "writer.add_text('Model/Info', f\"\"\"\n",
    "**Model Type**: {model_type}\n",
    "**Total Parameters**: {model_params:,}\n",
    "**Patch Size**: {getattr(model, 'patch_size', 'N/A')}\n",
    "**Embed Dim**: {getattr(model, 'embed_dim', getattr(model, 'dim', 'N/A'))}\n",
    "**Training Date**: {timestamp}\n",
    "\"\"\")\n",
    "\n",
    "writer.close()\n",
    "\n",
    "print(f\"\\n‚úÖ Training complete!\")\n",
    "print(f\"ü§ñ Model: {model_type}\")\n",
    "print(f\"üìä Parameters: {model_params:,}\")\n",
    "print(f\"üìÅ TensorBoard logs saved to: {writer.log_dir}\")\n",
    "print(f\"üåê Run TensorBoard to compare {model_type} with other models!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a60096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorBoard is available!\n"
     ]
    }
   ],
   "source": [
    "# Check if tensorboard is installed, if not install it\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    print(\"‚úÖ TensorBoard is available!\")\n",
    "except ImportError:\n",
    "    print(\"Tensorboard is not installed. Installing now...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'tensorboard'])\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    print(\"‚úÖ TensorBoard installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a2a179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard...\n",
      "Log directory: /home/moritz_s/Documents/RKIM_1/F_u_E_KI_Pipeline/KI_Training_Pipeline/runs\n",
      "TensorBoard will be available at: http://localhost:6006\n",
      "Press Ctrl+C in the terminal to stop TensorBoard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.19.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If TensorBoard started successfully, you can access it at:\n",
      "http://localhost:6006\n",
      "\n",
      "To stop TensorBoard, restart the kernel or use Ctrl+C in the terminal.\n"
     ]
    }
   ],
   "source": [
    "# Launch TensorBoard from within the notebook\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import threading\n",
    "import time\n",
    "\n",
    "def launch_tensorboard():\n",
    "    \"\"\"Launch TensorBoard in a separate thread\"\"\"\n",
    "    try:\n",
    "        # Get the current directory\n",
    "        current_dir = os.getcwd()\n",
    "        runs_dir = os.path.join(current_dir, 'runs')\n",
    "        \n",
    "        # Check if runs directory exists\n",
    "        if not os.path.exists(runs_dir):\n",
    "            print(f\"Warning: {runs_dir} directory not found. Make sure you have run the training loop first.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Starting TensorBoard...\")\n",
    "        print(f\"Log directory: {runs_dir}\")\n",
    "        print(\"TensorBoard will be available at: http://localhost:6006\")\n",
    "        print(\"Press Ctrl+C in the terminal to stop TensorBoard\")\n",
    "        \n",
    "        # Launch TensorBoard using Python module\n",
    "        cmd = [sys.executable, '-m', 'tensorboard.main', '--logdir', runs_dir, '--port', '6006']\n",
    "        process = subprocess.run(cmd, check=True)\n",
    "        \n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error starting TensorBoard: {e}\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nTensorBoard stopped by user\")\n",
    "\n",
    "# Start TensorBoard in a separate thread so it doesn't block the notebook\n",
    "tensorboard_thread = threading.Thread(target=launch_tensorboard, daemon=True)\n",
    "tensorboard_thread.start()\n",
    "\n",
    "# Give it a moment to start\n",
    "time.sleep(2)\n",
    "print(\"\\nIf TensorBoard started successfully, you can access it at:\")\n",
    "print(\"http://localhost:6006\")\n",
    "print(\"\\nTo stop TensorBoard, restart the kernel or use Ctrl+C in the terminal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add2b848",
   "metadata": {},
   "source": [
    "## üìä TensorBoard Anleitung\n",
    "\n",
    "### Was ist TensorBoard?\n",
    "TensorBoard ist ein Visualisierungstool f√ºr Machine Learning Experimente. Es hilft dir dabei:\n",
    "- **Trainingsverl√§ufe** zu visualisieren (Loss, Accuracy, etc.)\n",
    "- **Modellarchitekturen** zu betrachten\n",
    "- **Histogramme** von Gewichten und Gradienten zu analysieren\n",
    "- **Bilder und Embeddings** zu visualisieren\n",
    "\n",
    "### üöÄ Wie verwendest du TensorBoard?\n",
    "\n",
    "#### Schritt 1: Training ausf√ºhren\n",
    "Stelle sicher, dass du die Trainingszellen ausgef√ºhrt hast. Diese erstellen die Log-Dateien im `runs/` Ordner.\n",
    "\n",
    "#### Schritt 2: TensorBoard √∂ffnen\n",
    "- √ñffne deinen Browser\n",
    "- Gehe zu: `http://localhost:6006`\n",
    "- Du siehst jetzt deine Trainingsgraphen!\n",
    "\n",
    "### üîç Was siehst du in TensorBoard?\n",
    "- **SCALARS Tab**: Hier siehst du den Trainingsloss √ºber die Zeit\n",
    "- **GRAPHS Tab**: Hier kannst du die Modellarchitektur visualisieren\n",
    "- **DISTRIBUTIONS/HISTOGRAMS**: Gewichtsverteilungen (falls geloggt)\n",
    "\n",
    "2. **SCALARS Tab**: \n",
    "   - Du siehst einen Graphen namens \"Loss/Train\"\n",
    "   - Dieser zeigt, wie der Trainingsloss √ºber die 100 Batches sinkt (von ~2.5 auf ~2.0)\n",
    "   - Du siehst auch \"Final/TrainingLoss\" mit dem finalen Loss-Wert\n",
    "\n",
    "3. **Was die Graphen bedeuten**:\n",
    "   - X-Achse: Batch-Nummer (0 bis 100)\n",
    "   - Y-Achse: Loss-Wert\n",
    "   - Der Graph sollte eine fallende Tendenz zeigen ‚Üí das Modell lernt! üìà\n",
    "\n",
    "   ### üí° Tipps\n",
    "- TensorBoard aktualisiert sich automatisch, wenn neue Daten hinzugef√ºgt werden\n",
    "- Du kannst mehrere Experimente vergleichen, indem du verschiedene Ordner in `runs/` erstellst\n",
    "- Verwende aussagekr√§ftige Namen f√ºr deine Logs: `writer = SummaryWriter('runs/experiment_1')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0cf6c4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KI_Pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
